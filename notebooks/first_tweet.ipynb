{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dcd37cf",
   "metadata": {},
   "source": [
    "# First step with API Twitter\n",
    "The goal of this jupyternotebook is to perform basicmanipulation of the API Twitter.\n",
    "\n",
    "One can learn/find in this notebook how to:\n",
    "* make a request to get the tweets with the mention of `words` in the body text of tweets.\n",
    "* make a request to get the tweets of a certain `user`.\n",
    "* make a request to get the tweets in a certain date range (from `date_start` to `date_end`).\n",
    "\n",
    "## Authentification forehand\n",
    "The be able to perform the requests from the forged query, one needs to be identified regarding to his/her twitter developper application.\n",
    "\n",
    "According to the [Twitter Developper Plateform documentation](https://developer.twitter.com/en/docs/authentication/overview) the authentification ensure to secure the data available on the plateform through authenfitication.\n",
    "\n",
    "There are several authentification methods:\n",
    "* [**OAuth 1.0a User Context**](https://developer.twitter.com/en/docs/authentication/oauth-1-0a)\n",
    "* [**OAuth 2.0 Authentification**](https://developer.twitter.com/en/docs/authentication/oauth-2-0)\n",
    "    * [**Bearer Token**](https://developer.twitter.com/en/docs/authentication/oauth-2-0/application-only)\n",
    "    * [**OAuth 2.0 auth Code Flow with PKCE**](https://developer.twitter.com/en/docs/authentication/oauth-2-0/authorization-code)\n",
    "* [**Basic Authentification**](https://developer.twitter.com/en/docs/authentication/basic-auth)\n",
    "\n",
    "You can also (you must, it will be clearer after you read it) read the documentation about the [*Credential Handling*](https://github.com/twitterdev/search-tweets-python#credential-handling) to have few more informations about the credentials handling in a code point of view.\n",
    "\n",
    "The dictionnaries keys for AWS and Twitter API used here are expected to be:\n",
    "* `SEARCHTWEETS_ENDPOINT`\n",
    "* `SEARCHTWEETS_BEARER_TOKEN`\n",
    "* `SEARCHTWEETS_CONSUMER_KEY`\n",
    "* `SEARCHTWEETS_CONSUMER_SECRET`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6719ab-53bf-430e-acb5-47ee95aa875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searchtweets version: 1.1.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import searchtweets\n",
    "from searchtweets import ResultStream, gen_request_parameters, load_credentials, collect_results\n",
    "\n",
    "print('Searchtweets version:', searchtweets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b12bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look to the env variables:\n",
    "# os.environ\n",
    "\n",
    "##\n",
    "# /!\\ if you source your .envrc with the credentials in it, they will appeared here. BE SURE TO CLEAR OUTPUTS\n",
    "# If the credentials are not in os.environ, you can retrieved them using the functions \"retrieve_AWS_related\" and \"retrieved_TwitterAPI_related\"\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34c974-72bf-4d6a-ae57-a602f02a2c64",
   "metadata": {},
   "source": [
    "### Loading the credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda8f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_TwitterAPI_related(s_envrc: str) -> dict:\n",
    "    tmp = s_envrc.split('\\n')\n",
    "    lst_to_retrieve = ['SEARCHTWEETS_ENDPOINT',\n",
    "        'SEARCHTWEETS_BEARER_TOKEN',\n",
    "        'SEARCHTWEETS_CONSUMER_KEY',\n",
    "        'SEARCHTWEETS_CONSUMER_SECRET']\n",
    "    s_twitter_related = {}\n",
    "    for needle in lst_to_retrieve:\n",
    "        for s in tmp:\n",
    "            if s.find(needle) == 0:\n",
    "                key, val = s.split('=')\n",
    "                s_twitter_related[key] = val[1:-1]\n",
    "    return s_twitter_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a604ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Awful but it will work for now, if a (several) key(s) related to twitter API is (are) missing, it will try to find it in the `.envrc` file\n",
    "necessary_keys = ['SEARCHTWEETS_ENDPOINT', 'SEARCHTWEETS_BEARER_TOKEN', 'SEARCHTWEETS_CONSUMER_KEY', 'SEARCHTWEETS_CONSUMER_SECRET']\n",
    "\n",
    "if any([k in os.environ.keys() for k in necessary_keys]):\n",
    "    with open('../.envrc', 'r') as f:\n",
    "        content = f.read()\n",
    "    dct_twitterapi = retrieve_TwitterAPI_related(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a900fba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dct_twitterapi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdct_twitterapi\u001b[49m:\n\u001b[1;32m      2\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[key] \u001b[38;5;241m=\u001b[39m val\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dct_twitterapi' is not defined"
     ]
    }
   ],
   "source": [
    "for key, val in dct_twitterapi:\n",
    "    os.environ[key] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9101c4-013e-41d4-be83-7ea4a6ca2294",
   "metadata": {},
   "source": [
    "Now the necessary credentials should be in the environment and accessible to allow our authentification to Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f7485a-ec2e-4663-9e5b-8747143393e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If thecredentials are in a specific YAML file, those can be load directly from this file\n",
    "\n",
    "# Loading the credentials:\n",
    "# search_args = load_credentials(filename=\"./.searchtweets_credentials.yaml\",\n",
    "#                  yaml_key=\"search_tweets_v2_example\",\n",
    "#                  env_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c7c2fa2-3071-4f57-82fe-89adfd5cd6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cannot read file ~/.twitter_keys.yaml\n",
      "Error parsing YAML file; searching for valid environment variables\n",
      "Your credentials are not configured correctly and  you are missing a required field. Please see the  readme for proper configuration\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/goinfre/mdavid/v_sentimentalBB/lib/python3.8/site-packages/searchtweets/credentials.py:71\u001b[0m, in \u001b[0;36m_parse_credentials\u001b[0;34m(search_creds, api_version)\u001b[0m\n\u001b[1;32m     66\u001b[0m             search_creds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbearer_token\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _generate_bearer_token(\n\u001b[1;32m     67\u001b[0m                 search_creds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsumer_key\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     68\u001b[0m                 search_creds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsumer_secret\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     70\u001b[0m     search_args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbearer_token\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43msearch_creds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbearer_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: search_creds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: search_creds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m)}\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bearer_token'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m search_args \u001b[38;5;241m=\u001b[39m \u001b[43mload_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/goinfre/mdavid/v_sentimentalBB/lib/python3.8/site-packages/searchtweets/credentials.py:152\u001b[0m, in \u001b[0;36mload_credentials\u001b[0;34m(filename, yaml_key, env_overwrite)\u001b[0m\n\u001b[1;32m    148\u001b[0m env_vars \u001b[38;5;241m=\u001b[39m _load_env_credentials()\n\u001b[1;32m    149\u001b[0m merged_vars \u001b[38;5;241m=\u001b[39m (merge_dicts(yaml_vars, env_vars)\n\u001b[1;32m    150\u001b[0m                \u001b[38;5;28;01mif\u001b[39;00m env_overwrite\n\u001b[1;32m    151\u001b[0m                \u001b[38;5;28;01melse\u001b[39;00m merge_dicts(env_vars, yaml_vars))\n\u001b[0;32m--> 152\u001b[0m parsed_vars \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_vars\n",
      "File \u001b[0;32m/goinfre/mdavid/v_sentimentalBB/lib/python3.8/site-packages/searchtweets/credentials.py:79\u001b[0m, in \u001b[0;36m_parse_credentials\u001b[0;34m(search_creds, api_version)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour credentials are not configured correctly and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m you are missing a required field. Please see the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m readme for proper configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m search_args\n",
      "\u001b[0;31mKeyError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_args = load_credentials(filename=None)\n",
    "#search_args\n",
    "\n",
    "# will catch the necessary credentials from env,\n",
    "#this method can be used to avoid to use the custom parsing function retrieve_TwitterAPI_related"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6c8ef-c2a9-42af-88b0-42b90c3aa143",
   "metadata": {},
   "source": [
    "## Tweets with the mention of `words` in the body text of tweets.\n",
    "### Forging a query:\n",
    "There is 2 ways to interact with the Twitter API:\n",
    "* fast way: using `gen_request_parameters`\n",
    "* ResultStream: using `ResultStream` class object\n",
    "\n",
    "The first parameter of `gen_request_parameters` (or `gen_rule_payload`) must be a string representing what we call *Power track rule*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50568fb5-af92-4821-970d-607fc219201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gen_request_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb25c9ba-68ce-4662-8982-6fa96c476c6e",
   "metadata": {},
   "source": [
    "According to the [Developer Platform documentation](https://developer.twitter.com/en/docs/twitter-api/enterprise/historical-powertrack-api/guides/historical_powertrack_rules_and_filtering), PowerTrack allows to filter Twitter's full firehose.\n",
    "\n",
    "We can filter on a wide range of attributes:\n",
    "* geo-location,\n",
    "* language,\n",
    "* keyword,\n",
    "* hastag,\n",
    "* mention\n",
    "* ...\n",
    "\n",
    "See documentation [here](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/enterprise-operators) and especially [here](https://developer.twitter.com/en/docs/twitter-api/enterprise/powertrack-api/overview)\n",
    "\n",
    "There are many possible filtering actions, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea895c89-8e2c-4f6f-b1c6-8d69f21c672c",
   "metadata": {},
   "source": [
    "For the `start_date` and `end_date`, it has to be in UTC format accepted by the function `convert_utc_time`:\n",
    "\n",
    "![convert_utc_time](images/convert_utc_time.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6dc1c-593f-4105-b11f-004a6c08890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_time = e_time= None\n",
    "query = gen_request_parameters(\"EmmanuelMacron lang:fr\",\n",
    "                               results_per_call=10,\n",
    "                               granularity=None,\n",
    "                               start_time=s_time,\n",
    "                               end_time=e_time)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb9f4a-a36f-4b62-ad8f-b8f8f62085e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = collect_results(query, max_tweets=10, result_stream_args=search_args) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc230ac-cff5-42b7-bb5c-4d0bfc3b4b7f",
   "metadata": {},
   "source": [
    "### Remarks:\n",
    "How the return of collect_results are constructed ?\n",
    "\n",
    "* `tweets` is a list where each elements is a dictionary containing `max_tweets` number of tweets: the results are `batchs` of tweets.\n",
    "* Each batch is a dictionnary with 2 keys: \"data\" and \"metadata\".\n",
    "* `batch['data']` is a list of dictionaries corresponding to each tweets (`batch['data'][i]`).\n",
    "*  `batch['data'][i]['id']` is the tweet ID and `batch['data'][i]['text']` is the text of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb6067-5114-4e6c-95c4-618976ac8b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets[0]['data'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffdc12-d54c-470b-a5a8-3fa38e90e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda tweets, tweet_nb: tweets[0]['data'][tweet_nb]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db908d89-38ae-4738-a0fa-8c430e63c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(func(tweets, 2)[::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43963ace-7dae-4ce4-8579-b58203f4cfe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = tweets\n",
    "for element in request:\n",
    "    for id, tweet in enumerate(element['data']):\n",
    "        print(f\"Tweet n*{id}\")\n",
    "        print(tweet[\"text\"])\n",
    "        print(f\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d093c-50a7-4101-b139-269fca4a01ac",
   "metadata": {},
   "source": [
    "### Forging a query with `ResultStream`\n",
    "The `ResultStream` constructor needs at least the `endpoint` (*str*) and `rule_payload` (*dict* or *json*).\n",
    "There are also other parameters such as `username`, `password`, `bearer_token` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4fc588-2126-4367-8d02-a15eca8a2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ResultStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9b1af-c466-4c71-ab2d-64489894e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ResultStream(**search_args,\n",
    "                  request_parameters=query, # as mentioned by the doc, it can be a json.\n",
    "                 max_tweets=3,\n",
    "                 max_requests=1,\n",
    "                 output_format='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376075d-3f8d-476f-9506-134ade612c6c",
   "metadata": {},
   "source": [
    "When the ResultStream object is instanced, we can used its method `stream` which returns a `generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe8038-aa83-44d8-b3ea-c6604afde524",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in rs.stream():\n",
    "    print(ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babee4de-09a7-4e1d-80bb-ff01ec6fd64f",
   "metadata": {},
   "source": [
    "As mentioned in the documentation of the class, one can used a json file for `request_parameters` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f23e8-b0b6-425f-aabc-145dc9443621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae4318-87d5-46bf-8bb6-38c9d371c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a json file:\n",
    "dct_query = json.loads(query)\n",
    "\n",
    "with open('first_tweet.json', 'w') as outputfile:\n",
    "    json.dump(dct_query, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f10fd-2fc9-4b64-96d7-ff758d1f6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ResultStream(**search_args,\n",
    "                  request_parameters='first_tweet.json', # as mentioned by the doc, it can be a json.\n",
    "                 max_tweets=3,\n",
    "                 max_requests=1,\n",
    "                 output_format='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e563ac-9541-4030-ae3d-de431ffed136",
   "metadata": {},
   "source": [
    "It is not working because the documentation is not precise enough.\n",
    "\n",
    "It is dictonnary construct from a json file which works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb783e1-51b2-4011-bbdc-342ff700c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ResultStream(**search_args,\n",
    "                  request_parameters=dct_query, # as mentioned by the doc, it can be a json.\n",
    "                 max_tweets=3,\n",
    "                 max_requests=1,\n",
    "                 output_format='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ced3a6-f178-42af-9089-3e63e324fd41",
   "metadata": {},
   "source": [
    "### Tweet mentionning a user:\n",
    "\n",
    "Simply use `@user` or `{'from':user}` when forging the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a75c6f-d3ec-427b-b298-c59ae708f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = gen_request_parameters(\" from:JLMelenchon\",\n",
    "                               results_per_call=10,\n",
    "                               granularity=None)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd27356-5024-4c2a-902c-d5d50e8f30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = collect_results(query, max_tweets=3, result_stream_args=search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b595d62-0d76-46b9-a880-8a6090a67cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13b633-2e92-454a-8901-879ae33117e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ResultStream(**search_args,\n",
    "                  request_parameters={'query':'from:JLMelenchon'}, # as mentioned by the doc, it can be a json.\n",
    "                 max_tweets=3,\n",
    "                 max_requests=1,\n",
    "                 output_format='a')\n",
    "\n",
    "for ii in rs.stream():\n",
    "    print(ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffc592-17e1-4813-b40b-9957b0cb839b",
   "metadata": {},
   "source": [
    "If the query is incorrectly formated, one could get an HTTPError / Bad Request\n",
    "\n",
    "From the raised error:\n",
    "```\n",
    "HTTP Error code: 400: {\"errors\":[{\"parameters\":{\"from\":[\"JLMelenchon\"]},\"message\":\"The query parameter [from] is not one of [query,start_time,end_time,since_id,until_id,max_results,next_token,pagination_token,sort_order,expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields]\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"} | Bad Request\n",
    " Request payload: {'query': '', 'from': 'JLMelenchon'}\n",
    "Quitting... \n",
    "```\n",
    "One can see that we can provided the following keys in the dictionary:\n",
    "* **query**,\n",
    "* **start_time**,\n",
    "* **end_time**,\n",
    "* **since_id**,\n",
    "* **until_id**,\n",
    "* **max_results**,\n",
    "* **next_token**,\n",
    "* **pagination_token**,\n",
    "* **sort_order**,\n",
    "* **expansions**,\n",
    "* **tweet.fields**,\n",
    "* **media.fields**,\n",
    "* **poll.fields**,\n",
    "* **place.fields**,\n",
    "* **user.fields**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b0ace-f579-4652-a297-80af0031582d",
   "metadata": {},
   "source": [
    "### Request to get the tweets in a certain date range (from date_start to date_end).\n",
    "For the starting and ending time, one has just to give the date in one of the following format:\n",
    "- YYYYmmDDHHMM\n",
    "- YYYY-mm-DD\n",
    "- YYYY-mm-DD HH:MM\n",
    "- YYYY-mm-DDTHH:MM\n",
    "\n",
    "\n",
    "**Remark:**\n",
    "\n",
    "We cannot request with date older than 7 days ago, otherwise one will get this type of warning:\n",
    "\n",
    "```\n",
    " HTTP Error code: 400: {\"errors\":[{\"parameters\":{\"start_time\":[\"2022-02-02T00:00Z\"]},\"message\":\"Invalid 'start_time':'2022-02-02T00:00Z'. 'start_time' must be on or after 2022-03-01T18:59Z\"},{\"parameters\":{\"end_time\":[\"2022-02-10T00:00Z\"]},\"message\":\"Invalid 'end_time':'2022-02-10T00:00Z'. 'end_time' must be on or after 2022-03-01T18:59Z\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"} | Bad Request\n",
    " Request payload: {'query': 'EmmanuelMacron lang:fr', 'start_time': '2022-02-02T00:00:00Z', 'end_time': '2022-02-10T00:00:00Z', 'max_results': 10}\n",
    "Quitting.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3177252-293f-4774-85d5-24032388ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YYY-mm-DD HH:MM\n",
    "start_time = '2022-03-01'\n",
    "end_time= '2022-03-07'\n",
    "query = gen_request_parameters(\"EmmanuelMacron lang:fr\",\n",
    "                               results_per_call=10,\n",
    "                               granularity=None,\n",
    "                               start_time=start_time,\n",
    "                               end_time=end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3967000-5cb5-46c7-964d-ce437e4c793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = collect_results(query, max_tweets=3, result_stream_args=search_args)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe24742-0c26-4a57-a396-9d002bcd486e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
